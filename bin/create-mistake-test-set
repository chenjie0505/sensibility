#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

# Copyright 2017 Eddie Antonio Santos <easantos@ualberta.ca>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Selects N random mistakes from the mistakes database and creates a directory
holding them.

Usage:

    create-mistake-test-set SIZE DESTINATION
    create-mistake-test-set --all DESTINATION
"""

import argparse
import csv
import sqlite3
from pathlib import Path

from tqdm import tqdm

from sensibility._paths import MISTAKE_FILE


# TODO: get the ACTUAL error from the blackbox data.
FIELD_NAMES = [
    'sfid', 'meid',
    'mistake', 'mistake_index',
    'line_no',
    'old_token',
    'fix', 'fix_index',
    'new_token',
]

parser = argparse.ArgumentParser()
group = parser.add_mutually_exclusive_group(required=True)
group.add_argument('--all', action='store_true')
group.add_argument('size', type=int, help="how many mistakes to sample", nargs='?')
parser.add_argument('destination', type=Path, help="where to dump the files")
args = parser.parse_args()

assert args.all or args.size >= 0

conn = sqlite3.connect(str(MISTAKE_FILE))

# Creates a BRAND NEW directory as the destination.
# Intentionally do not catch an error it the directory already exists.
root = args.destination
root.mkdir()

# Ensure we can write to the CSV file.
csv_file = open(root / 'mistakes.csv', 'w')
# I pass the entire row from the database verbatim, so ignore any extra
# columns.
writer = csv.DictWriter(csv_file, FIELD_NAMES, extrasaction='ignore')
writer.writeheader()

if args.all:
    # Get ALL of the mistakes from the database.
    files = tuple(conn.execute('''
        SELECT source_file_id, before_id FROM edit
    '''))
else:
    # Get a list of random (one-token) mistakes from the database.
    files = tuple(conn.execute('''
        SELECT source_file_id, before_id
          FROM edit
         ORDER BY RANDOM()
         LIMIT ?
    ''', (args.size,)))

# Optimization: Create a temporary table with the subset. This speeds up
# things considerably.
conn.execute('''
    CREATE TEMPORARY TABLE query(source_file_id, before_id,
    PRIMARY KEY (source_file_id, before_id))
''')
conn.executemany('''
    INSERT INTO query (source_file_id, before_id)
    VALUES (?, ?)
''', files)

# Now we can treat each row like a dictionary.
conn.row_factory = sqlite3.Row

# Now get all the information in one go
rows = conn.execute('''
    SELECT edit.source_file_id as sfid,
           edit.before_id as meid,
           before, after,
           mistake, mistake_index, fix, fix_index,
           line_no, old_token, new_token
      FROM query NATURAL JOIN mistake NATURAL JOIN edit
''')

code_to_word = dict(i='insertion', x='deletion', s='substitution')

# For each random mistake, create the file.
for row in tqdm(rows, total=len(files)):
    sfid, meid = str(row['sfid']), str(row['meid'])

    # Write out the contents
    path = root / sfid / meid
    path.mkdir(parents=True)

    with open(path / 'before.java', 'wb') as file:
        file.write(row['before'])
    with open(path / 'after.java', 'wb') as file:
        file.write(row['after'])

    # Let's modify the dictionary, not dictionary!
    row_dict = dict(row)
    row_dict['fix'] = code_to_word[row['fix']]
    row_dict['mistake'] = code_to_word[row['mistake']]

    writer.writerow(dict(row))
