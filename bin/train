#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

# Copyright 2017 Eddie Antonio Santos <easantos@ualberta.ca>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import logging
from typing import Set
from pathlib import Path

from sensibility.language import language
from sensibility.model.lstm import ModelDescription, layers
from sensibility._paths import (
    EVALUATION_DIR, get_validation_set_path, get_training_set_path
)

# TODO: Support multiple models?

# Based on emprical findings: this one gets to min loss pretty quickly,
# and is usable.
HIDDEN_LAYERS = (300, 300)
# Based on White et al. 2015
CONTEXT_LENGTH = 20
# This is arbitrary, but it should be fairly small.
BATCH_SIZE = 512

# Create the argument parser.
# TODO: infer from language.
parser = argparse.ArgumentParser(description='Train from corpus '
                                 'of vectors, with fold assignments')
parser.add_argument('-i', '--partition', type=int, required=True,
                    help='which partition this is')
group = parser.add_mutually_exclusive_group(required=True)
group.add_argument('--backwards', action='store_true')
group.add_argument('--forwards', action='store_false', dest='backwards')
parser.add_argument('--hidden-layers', type=layers, default=HIDDEN_LAYERS,
                    help=f"default: {HIDDEN_LAYERS}")
parser.add_argument('--context-length', type=int, default=CONTEXT_LENGTH,
                    help=f"default: {CONTEXT_LENGTH}")
parser.add_argument('--batch-size', type=int, default=BATCH_SIZE,
                    help=f"default: {BATCH_SIZE}")
parser.add_argument('--base-dir', type=Path, default=EVALUATION_DIR,
                    help=f"default: {EVALUATION_DIR}")


def slurp(filename: Path) -> Set[str]:
    with open(filename, 'r') as f:
        return set(line.strip() for line in f if line.strip() != '')


if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    args = parser.parse_args()
    # Determine language first!
    model = ModelDescription(
        partition=args.partition,
        training_set=slurp(get_training_set_path(args.partition)),
        validation_set=slurp(get_validation_set_path(args.partition)),
        backwards=args.backwards,
        base_dir=args.base_dir / language.id / 'models',
        batch_size=args.batch_size,
        context_length=args.context_length,
        hidden_layers=args.hidden_layers,
        vectors_path=args.base_dir / language.id / 'vectors.sqlite3'
    )

    model.train()
